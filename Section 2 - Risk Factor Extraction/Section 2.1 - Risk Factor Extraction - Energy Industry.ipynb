{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209b9203",
   "metadata": {},
   "source": [
    "# Section 2 Risk Factor Extraction\n",
    "\n",
    "In section 1, we have downloaded the fincancial reports from 2022Q1 to 2023Q3. In this section, we are going to extract the risk factor text from each of these files. According to the requirement of the 10-K form given by SEC (https://www.sec.gov/files/form10-k.pdf), there is an section named \"Item 1A. Risk Factors\" included in the form  which shows the potential risks faced by the company. Therefore, it is important for us to filter and cleanse the text from this part so that we can use it for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66732524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4583031",
   "metadata": {},
   "source": [
    "# 2.1 Energy & Transportation Industry (1311, 1389, 4911)\n",
    "\n",
    "In this section, we only focus on companies in Energy & Transportation Industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5597c74",
   "metadata": {},
   "source": [
    "## 2.1.1 Industry 1311\n",
    "\n",
    "### 1. Read in the files and store in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0f61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"../Section 1 - Datasets Downloads and Preparation/Downloaded Financial Reports/Energy Industry/Industry_1311/\"\n",
    "fileName_lst = os.listdir(folderPath)\n",
    "filePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in fileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(folderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        fileText = file.read()\n",
    "    filePair_dict[fileName] = fileText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11835912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0000007332-23-000005.txt', '0000010254-23-000058.txt', '0000023194-23-000009.txt', '0000033213-23-000008.txt', '0000061398-23-000011.txt', '0000077159-23-000003.txt', '0000077877-23-000012.txt', '0000101778-23-000030.txt', '0000351817-23-000032.txt', '0000717423-23-000015.txt', '0000797468-23-000011.txt', '0000798949-23-000015.txt', '0000821189-23-000015.txt', '0000821483-23-000008.txt', '0000844965-23-000009.txt', '0000858470-23-000011.txt', '0000893538-23-000014.txt', '0000895126-23-000022.txt', '0000928022-23-000017.txt', '0000945764-23-000028.txt', '0000950170-23-002852.txt', '0000950170-23-003794.txt', '0000950170-23-004459.txt', '0000950170-23-004687.txt', '0000950170-23-005278.txt', '0000950170-23-006714.txt', '0001001614-23-000011.txt', '0001017386-22-000147.txt', '0001038357-23-000039.txt', '0001062993-23-007669.txt', '0001070412-23-000015.txt', '0001072613-23-000285.txt', '0001096906-22-000878.txt', '0001096906-23-000666.txt', '0001104485-23-000041.txt', '0001185185-22-000456.txt', '0001185185-22-000459.txt', '0001185185-23-000244.txt', '0001185185-23-000305.txt', '0001193125-22-113187.txt', '0001193125-23-088251.txt', '0001199835-22-000539.txt', '0001213900-22-019928.txt', '0001213900-22-037982.txt', '0001213900-23-025590.txt', '0001214659-23-004059.txt', '0001273441-23-000005.txt', '0001362705-23-000018.txt', '0001376474-23-000173.txt', '0001387131-23-004228.txt', '0001393905-22-000107.txt', '0001437749-22-008152.txt', '0001437749-22-016285.txt', '0001437749-22-021365.txt', '0001437749-23-004361.txt', '0001437749-23-007712.txt', '0001437749-23-008767.txt', '0001437749-23-008793.txt', '0001477932-22-001994.txt', '0001477932-22-002510.txt', '0001477932-22-003925.txt', '0001477932-22-004557.txt', '0001477932-22-004724.txt', '0001477932-22-005494.txt', '0001477932-23-001554.txt', '0001477932-23-001745.txt', '0001486159-23-000004.txt', '0001493152-22-013400.txt', '0001493152-22-016856.txt', '0001493152-22-017850.txt', '0001493152-23-010237.txt', '0001493152-23-010392.txt', '0001509589-23-000017.txt', '0001509991-23-000021.txt', '0001515971-22-000125.txt', '0001520006-23-000056.txt', '0001528129-23-000048.txt', '0001539838-23-000022.txt', '0001553350-22-000785.txt', '0001558370-22-014404.txt', '0001558370-23-001378.txt', '0001558370-23-001907.txt', '0001558370-23-003153.txt', '0001558370-23-003321.txt', '0001558370-23-004481.txt', '0001558370-23-004735.txt', '0001558370-23-005138.txt', '0001564590-23-002595.txt', '0001602065-23-000007.txt', '0001609253-23-000017.txt', '0001628280-23-004630.txt', '0001628280-23-005790.txt', '0001628280-23-007323.txt', '0001628280-23-008082.txt', '0001640334-22-001335.txt', '0001654954-22-004427.txt', '0001654954-23-003759.txt', '0001658566-23-000019.txt', '0001673379-23-000003.txt', '0001698990-23-000010.txt', '0001705873-23-000026.txt', '0001784031-23-000007.txt', '0001784031-23-000008.txt', '0001829126-23-002407.txt', '0001866175-23-000010.txt', '0001944558-23-000024.txt'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePair_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430007e8",
   "metadata": {},
   "source": [
    "### 2. Extract the raw risk factor text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5e35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    # replace the tag included by <> to a \\ \n",
    "    pattern1 = r'<[^>]*>'\n",
    "    cleanText = re.sub(pattern1, \"|\", text)\n",
    "    \n",
    "    # replace the multiple continued \\ to a single \\\n",
    "    cleanText = re.sub(r'\\s*\\|+\\s*', '|', cleanText)\n",
    "    cleanText = re.sub(r'\\|+', '|', cleanText)\n",
    "    \n",
    "    # replace the unicode\n",
    "    cleanText = html.unescape(cleanText)\n",
    "    \n",
    "    # remove the line break\n",
    "    cleanText = cleanText.replace('\\n', '')\n",
    "    # remove the pure numbers text between \\\n",
    "    cleanText = re.sub(r'\\|(\\d+)\\|', '|', cleanText)\n",
    "    # remove the unrecognized string\n",
    "    cleanText = re.sub(r'|\\xa0\\|', '', cleanText)\n",
    "    cleanText = re.sub(r'|\\xa0|', '', cleanText)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d16e20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_main_body(text):\n",
    "    lastContentInTC_lst = [\">form 10-k summary<\", \">item 16. form 10-k summary<\", r\">exhibits, financial statement schedules<\", \n",
    "                           r\">exhibits and financial statement schedules<\", r\"exhibits and financial statement schedules <\",\n",
    "                           \">exhibits<\"]\n",
    "    start_idx = -1\n",
    "    for content in lastContentInTC_lst:\n",
    "        if content in text.lower():\n",
    "            start_idx = text.lower().find(content)\n",
    "            break\n",
    "            \n",
    "    if start_idx == -1:\n",
    "        return False\n",
    "    \n",
    "    mainBody = text[start_idx:]\n",
    "    mainBody = html.unescape(mainBody)\n",
    "    return mainBody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc79098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_risk_factors(mainBody, fileName):\n",
    "    # match the risk factor\n",
    "    keywordMatch = re.findall(r\">item 1a.\\s+risk factors\\.?\\<\", mainBody.lower())\n",
    "    \n",
    "    # if fail to match the pattern, the pattern might be segmented be some html tags, so re-match\n",
    "    if not keywordMatch:\n",
    "        keyword = seperated_keyword_rematch(mainBody)\n",
    "        \n",
    "    # if match the pattern successfully, just keep the keyword of risk factor\n",
    "    else:\n",
    "        keyword = keywordMatch[0]\n",
    "    \n",
    "    # check if match successfully\n",
    "    if not keyword:\n",
    "        return False\n",
    "    keywordCheck_lst = [\"item\", r\"item 1a\\.?\", \"risk\", \"factors\", \"risk factors\"]\n",
    "    if keyword in keywordCheck_lst:\n",
    "        print(\"Warning: It is better to check whether the extraction is correct manually for file\", {fileName})\n",
    "    \n",
    "    # match the next section of the risk factor\n",
    "    nextSectionPattern_lst = [r\">item 1b.\\s+unresolved staff comments\\.?\\<\", r\">item 2.\\s+description of property\\.?\\<\"]\n",
    "    for pattern in nextSectionPattern_lst:\n",
    "        nextSectionMatch = re.findall(pattern, mainBody.lower())\n",
    "        \n",
    "        # if fail to match the pattern, the pattern might be segmented be some html tags, so re-match\n",
    "        if not nextSectionMatch:\n",
    "            nextSection = seperated_next_section_rematch(mainBody, pattern)\n",
    "            # if re-match successfully, jump out of the loop\n",
    "            if nextSection:\n",
    "                break\n",
    "        \n",
    "        # if match the pattern successfully, just keep the next section keyword and jump out of the loop\n",
    "        else:\n",
    "            nextSection = nextSectionMatch[0]\n",
    "            break\n",
    "    \n",
    "    # check if match successfully\n",
    "    if not nextSection:\n",
    "        return False\n",
    "    \n",
    "    # if match successfully, extract the risk factor\n",
    "    start_idx = mainBody.lower().find(keyword) # start index is the position of the keyword occured in the main body\n",
    "    end_idx = mainBody.lower().find(nextSection) # end index is the position of the next section begin in the main body\n",
    "    riskFactors = mainBody[start_idx: end_idx]\n",
    "    return riskFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8609aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperated_keyword_rematch(mainBody):\n",
    "    cleanedMainBody = remove_tags(mainBody)\n",
    "    keywordMatch = re.findall(r\"i\\|?t\\|?e\\|?m\\|?\\s+\\|?1\\|?a\\|?.\\|?\\s+\\|?r\\|?i\\|?s\\|?k\\|?\\s+\\|?f\\|?a\\|?c\\|?t\\|?o\\|?r\\|?s\\.?\", cleanedMainBody.lower())\n",
    "    \n",
    "    # check if re-match the keyword of risk factor successfully\n",
    "    if not keywordMatch:\n",
    "        return False\n",
    "    \n",
    "    # if re-match successfully, use the longer segmentation as the keyword of the risk factor\n",
    "    reMatchedKeyword = max(keywordMatch[0].split('|'), key=len)\n",
    "    return reMatchedKeyword\n",
    "    \n",
    "def seperated_next_section_rematch(mainBody, nextSectionPattern):\n",
    "    # cleanse the main body text\n",
    "    cleanedMainBody = remove_tags(mainBody)\n",
    "    \n",
    "    # edit the pattern \n",
    "    edittedPattern = nextSectionPattern.replace(r\">\", \"\").replace(r\"\\s+\", \" \").replace(r\"\\.?\\<\", \"\")\n",
    "    edittedPattern = \"\\|?\".join(edittedPattern)\n",
    "    edittedPattern = r\"{}\\.?\".format(edittedPattern)\n",
    "    pattern = edittedPattern.replace(\" \", \"\\s?+\")\n",
    "    nextSectionMatch = re.findall(pattern, cleanedMainBody.lower())\n",
    "    \n",
    "    # check if re-match the keyword of next section successfully\n",
    "    if not nextSectionMatch:\n",
    "        return False\n",
    "    \n",
    "    # if re-match successfully, use the longer segmentation as the keyword of the next section \n",
    "    reMatchedNextSection = max(nextSectionMatch[0].split('|'), key=len)\n",
    "    return reMatchedNextSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c7e086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extraction is failed for {'0000023194-23-000009.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000033213-23-000008.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000798949-23-000015.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000821483-23-000008.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000895126-23-000022.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000950170-23-002852.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000950170-23-004687.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001017386-22-000147.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001070412-23-000015.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001072613-23-000285.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001096906-22-000878.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001096906-23-000666.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001104485-23-000041.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001185185-22-000459.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001193125-22-113187.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001193125-23-088251.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001199835-22-000539.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001213900-22-037982.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001213900-23-025590.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001214659-23-004059.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001376474-23-000173.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001387131-23-004228.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001393905-22-000107.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001437749-22-016285.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-22-021365.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-23-007712.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-23-008767.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001477932-22-001994.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001477932-22-002510.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001477932-22-003925.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001477932-22-004557.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001477932-22-004724.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001477932-22-005494.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001477932-23-001554.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001477932-23-001745.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001493152-22-013400.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001493152-22-016856.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001493152-22-017850.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001493152-23-010237.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001493152-23-010392.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001509589-23-000017.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001520006-23-000056.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001528129-23-000048.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001553350-22-000785.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-22-014404.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-23-001378.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001558370-23-003153.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-23-004481.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-23-004735.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001564590-23-002595.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001609253-23-000017.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001628280-23-005790.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001673379-23-000003.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001784031-23-000007.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001784031-23-000008.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001829126-23-002407.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001866175-23-000010.txt'} because of the error in extracting risk factors.\n"
     ]
    }
   ],
   "source": [
    "for key, value in filePair_dict.items():\n",
    "    fileName = key\n",
    "    fileText = value\n",
    "    mainBody = separate_main_body(fileText) # separate the original text as the table of content and the main body.\n",
    "    \n",
    "    if not mainBody:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in seperating main body.\")\n",
    "        continue\n",
    "    \n",
    "    riskText = extract_risk_factors(mainBody, fileName) # extract the risk related text\n",
    "    if not riskText:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in extracting risk factors.\")\n",
    "    else:\n",
    "        riskFilePath = \"Risk Factor Text/Energy Industry/Industry_1311/Raw Text/\" + fileName\n",
    "        with open(riskFilePath, 'w', encoding='utf-8') as file:\n",
    "            file.write(riskText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243a5e11",
   "metadata": {},
   "source": [
    "### 3. Extract the subjects from raw risk factors text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116b58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_subjects(riskFactors, subjectFormat):\n",
    "    soup = BeautifulSoup(riskFactors, 'html.parser')\n",
    "    subject_lst = []\n",
    "    for span in soup.find_all('span'):\n",
    "        style = span.get('style')\n",
    "        if style and subjectFormat in style:\n",
    "            subject_lst.append(span.get_text())\n",
    "    return subject_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c6f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTextFolderPath = \"Risk Factor Text/Energy Industry/Industry_1311/Raw Text/\"\n",
    "rawTextFileName_lst = os.listdir(rawTextFolderPath)\n",
    "rawTextFilePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in rawTextFileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(rawTextFolderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        rawText = file.read()\n",
    "    rawTextFilePair_dict[fileName] = rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e115c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject fail to extract for {'0001062993-23-007669.txt'}\n",
      "The subject fail to extract for {'0001185185-22-000456.txt'}\n",
      "The subject fail to extract for {'0001185185-23-000244.txt'}\n",
      "The subject fail to extract for {'0001185185-23-000305.txt'}\n",
      "The subject fail to extract for {'0001213900-22-019928.txt'}\n",
      "The subject fail to extract for {'0001437749-22-008152.txt'}\n",
      "The subject fail to extract for {'0001437749-23-004361.txt'}\n",
      "The subject fail to extract for {'0001437749-23-008793.txt'}\n",
      "The subject fail to extract for {'0001515971-22-000125.txt'}\n",
      "The subject fail to extract for {'0001640334-22-001335.txt'}\n",
      "The subject fail to extract for {'0001654954-22-004427.txt'}\n",
      "The subject fail to extract for {'0001654954-23-003759.txt'}\n"
     ]
    }
   ],
   "source": [
    "subjectFormat_lst = [\"font-weight:700\", \"font-weight:bold\"]\n",
    "for key, value in rawTextFilePair_dict.items():\n",
    "    fileName = key\n",
    "    rawText = value\n",
    "    \n",
    "    i = 0\n",
    "    subject_lst = []\n",
    "    \n",
    "    while not subject_lst:\n",
    "        subjectFormat = subjectFormat_lst[i]\n",
    "        subject_lst = extract_subjects(rawText, subjectFormat)\n",
    "        i += 1\n",
    "        if i >= len(subjectFormat_lst):\n",
    "            break\n",
    "        \n",
    "    if not subject_lst:\n",
    "        print(\"The subject fail to extract for\", {fileName})\n",
    "    else:\n",
    "        subjectFolder = \"Risk Factor Text/Energy Industry/Industry_1311/Subject/\"\n",
    "        subjectFilePath = subjectFolder + str(fileName)\n",
    "        with open(subjectFilePath, 'w', encoding='utf-8') as file:\n",
    "            for item in subject_lst:\n",
    "                file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a084bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325fcf7c",
   "metadata": {},
   "source": [
    "## 2.1.2 Industry 1389\n",
    "\n",
    "### 1. Read in the files and store in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7ba613",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"../Section 1 - Datasets Downloads and Preparation/Downloaded Financial Reports/Energy Industry/Industry_1389/\"\n",
    "fileName_lst = os.listdir(folderPath)\n",
    "filePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in fileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(folderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        fileText = file.read()\n",
    "    filePair_dict[fileName] = fileText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617fde9",
   "metadata": {},
   "source": [
    "### 2. Extract the raw risk factor text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a4b468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extraction is failed for {'0000045012-23-000011.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000073756-23-000009.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000866829-23-000010.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000950170-23-010960.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-22-016757.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-23-004408.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001437749-23-008841.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001532286-23-000005.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-23-001765.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001558370-23-002171.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001558370-23-003281.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001564590-23-000762.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001738827-23-000014.txt'} because of the error in extracting risk factors.\n"
     ]
    }
   ],
   "source": [
    "for key, value in filePair_dict.items():\n",
    "    fileName = key\n",
    "    fileText = value\n",
    "    mainBody = separate_main_body(fileText) # separate the original text as the table of content and the main body.\n",
    "    \n",
    "    if not mainBody:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in seperating main body.\")\n",
    "        continue\n",
    "    \n",
    "    riskText = extract_risk_factors(mainBody, fileName) # extract the risk related text\n",
    "    if not riskText:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in extracting risk factors.\")\n",
    "    else:\n",
    "        riskFilePath = \"Risk Factor Text/Energy Industry/Industry_1389/Raw Text/\" + fileName\n",
    "        with open(riskFilePath, 'w', encoding='utf-8') as file:\n",
    "            file.write(riskText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b7f7e",
   "metadata": {},
   "source": [
    "### 3. Extract the subjects from raw risk factors text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e5c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTextFolderPath = \"Risk Factor Text/Energy Industry/Industry_1389/Raw Text/\"\n",
    "rawTextFileName_lst = os.listdir(rawTextFolderPath)\n",
    "rawTextFilePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in rawTextFileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(rawTextFolderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        rawText = file.read()\n",
    "    rawTextFilePair_dict[fileName] = rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5659c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject fail to extract for {'0001692427-23-000008.txt'}\n"
     ]
    }
   ],
   "source": [
    "subjectFormat_lst = [\"font-weight:700\", \"font-weight:bold\"]\n",
    "for key, value in rawTextFilePair_dict.items():\n",
    "    fileName = key\n",
    "    rawText = value\n",
    "    \n",
    "    i = 0\n",
    "    subject_lst = []\n",
    "    \n",
    "    while not subject_lst:\n",
    "        subjectFormat = subjectFormat_lst[i]\n",
    "        subject_lst = extract_subjects(rawText, subjectFormat)\n",
    "        i += 1\n",
    "        if i >= len(subjectFormat_lst):\n",
    "            break\n",
    "        \n",
    "    if not subject_lst:\n",
    "        print(\"The subject fail to extract for\", {fileName})\n",
    "    else:\n",
    "        subjectFolder = \"Risk Factor Text/Energy Industry/Industry_1389/Subject/\"\n",
    "        subjectFilePath = subjectFolder + str(fileName)\n",
    "        with open(subjectFilePath, 'w', encoding='utf-8') as file:\n",
    "            for item in subject_lst:\n",
    "                file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d6daf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5cf34",
   "metadata": {},
   "source": [
    "## 2.1.3 Industry 4911\n",
    "\n",
    "### 1. Read in the files and store in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e84be240",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPath = \"../Section 1 - Datasets Downloads and Preparation/Downloaded Financial Reports/Energy Industry/Industry_4911/\"\n",
    "fileName_lst = os.listdir(folderPath)\n",
    "filePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in fileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(folderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        fileText = file.read()\n",
    "    filePair_dict[fileName] = fileText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc787b",
   "metadata": {},
   "source": [
    "### 2. Extract the raw risk factor text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcec4f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extraction is failed for {'0000072741-23-000004.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000784977-23-000005.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000827052-23-000010.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000936340-23-000073.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0000950170-23-003912.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0000950170-23-007785.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001013871-23-000004.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001089819-23-000003.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001108426-23-000006.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001130310-23-000013.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001193125-23-083685.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001493152-22-019173.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001493152-23-010282.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001567683-23-000011.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001628280-23-009308.txt'} because of the error in extracting risk factors.\n",
      "The extraction is failed for {'0001637757-23-000004.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001683168-22-004681.txt'} because of the error in seperating main body.\n",
      "The extraction is failed for {'0001692819-23-000005.txt'} because of the error in extracting risk factors.\n"
     ]
    }
   ],
   "source": [
    "for key, value in filePair_dict.items():\n",
    "    fileName = key\n",
    "    fileText = value\n",
    "    mainBody = separate_main_body(fileText) # separate the original text as the table of content and the main body.\n",
    "    \n",
    "    if not mainBody:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in seperating main body.\")\n",
    "        continue\n",
    "    \n",
    "    riskText = extract_risk_factors(mainBody, fileName) # extract the risk related text\n",
    "    if not riskText:\n",
    "        print(\"The extraction is failed for\", {fileName}, \"because of the error in extracting risk factors.\")\n",
    "    else:\n",
    "        riskFilePath = \"Risk Factor Text/Energy Industry/Industry_4911/Raw Text/\" + fileName\n",
    "        with open(riskFilePath, 'w', encoding='utf-8') as file:\n",
    "            file.write(riskText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee3a1d",
   "metadata": {},
   "source": [
    "### 3. Extract the subjects from raw risk factors text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb92ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTextFolderPath = \"Risk Factor Text/Energy Industry/Industry_4911/Raw Text/\"\n",
    "rawTextFileName_lst = os.listdir(rawTextFolderPath)\n",
    "rawTextFilePair_dict = {} # filePair stores the file name and the corresponding file text.\n",
    "for fileName in rawTextFileName_lst:  \n",
    "    # encode each document\n",
    "    filePath = str(rawTextFolderPath) + str(fileName)    \n",
    "    with open(filePath, 'r', encoding='utf-8') as file:\n",
    "        rawText = file.read()\n",
    "    rawTextFilePair_dict[fileName] = rawText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25281160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject fail to extract for {'0001193311-23-000005.txt'}\n",
      "The subject fail to extract for {'0001437749-23-004477.txt'}\n"
     ]
    }
   ],
   "source": [
    "subjectFormat_lst = [\"font-weight:700\", \"font-weight:bold\"]\n",
    "for key, value in rawTextFilePair_dict.items():\n",
    "    fileName = key\n",
    "    rawText = value\n",
    "    \n",
    "    i = 0\n",
    "    subject_lst = []\n",
    "    \n",
    "    while not subject_lst:\n",
    "        subjectFormat = subjectFormat_lst[i]\n",
    "        subject_lst = extract_subjects(rawText, subjectFormat)\n",
    "        i += 1\n",
    "        if i >= len(subjectFormat_lst):\n",
    "            break\n",
    "        \n",
    "    if not subject_lst:\n",
    "        print(\"The subject fail to extract for\", {fileName})\n",
    "    else:\n",
    "        subjectFolder = \"Risk Factor Text/Energy Industry/Industry_4911/Subject/\"\n",
    "        subjectFilePath = subjectFolder + str(fileName)\n",
    "        with open(subjectFilePath, 'w', encoding='utf-8') as file:\n",
    "            for item in subject_lst:\n",
    "                file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f43da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
